>[!cite]
>正确的判断来自经验，而经验来自错误的判断。

## 交叉熵损失函数

交叉熵的公式为（采用 one-hot 编码）

$$
\mathcal L=-Observe_i\log(Predict_i)
$$

交叉熵就是负对数似然函数，因此最小化交叉熵就是最大化似然函数。

## Logistic 回归

Logistic 回归使用激活函数将线性函数值挤压到$(0,1)$之间。

激活函数是 logistic 函数，也叫 sigmoid 函数。

损失函数采用交叉熵损失函数。

## Softmax 回归

Softmax 回归也称为多类 Logistic 回归，是它在多分类问题上的推广。

激活函数采用 Softmax 函数，损失函数采用交叉熵损失函数。

Softmax 在多分类时，每类输出值得大小可以认为是该类出现的概率

另外，Softmax 回归对所有的权重向量减去同一个$\boldsymbol v$，不改变函数值。可以利用这个特性来正则化约束参数来避免数值计算时数据溢出的问题。

## 支持向量机

激活函数：符号函数

损失函数：平方损失函数

支持向量机三宝

1. 间隔
2. 对偶
3. 核技巧

KTT 条件

## 感知机

感知机是生物学中神经元的抽象。数学模型为

$$
y=f(wx+b)
$$

其中 $f$ 为激活函数，$w$ 为权重（weight），$b$ 为偏置（bias）。
