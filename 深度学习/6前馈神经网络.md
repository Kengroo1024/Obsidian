---
ttite: 前馈神经网络
date: 2024-3-24
categories:
  - 深度学习
---

## 激活函数

激活函数的特征

1. 非线性
2. 几乎处处可导
3. 导数要尽量简单
4. 导数不能太大，也不能太小，更不能无界

## S型曲线

### Logistic函数

定义

$$
\mathrm{logistic}(x)=\dfrac{1}{1+\mathrm{e}^{-x}}
$$

### tanh双曲正切函数

定义

$$
\tanh(x)=\dfrac{\mathrm{e}^x-\mathrm{e}^{-x}}{\mathrm{e}^x+\mathrm{e}^{-x}}
$$

有

$$
\tanh(x)=2\ \mathrm{logistic}(x)-1
$$


## 斜坡函数

### Relu函数

$$
\mathrm{Relu}=\max\{0,x\}
$$

### swish函数

$$
\mathrm{swish}(x)=x\ \mathrm{logistic}(\beta x)
$$

### Gelu函数

$$
\mathrm{Gelu}(x)=x\ \mathrm{erf}(x)
$$

## 前馈神经网络

网络中无环的，相邻的两层的神经元全连接的神经网络。前馈神经网络中无反馈，信号单向传播。